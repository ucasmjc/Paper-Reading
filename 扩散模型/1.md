# LABEL-EFFICIENT SEMANTIC SEGMENTATION WITH DIFFUSION MODELS(2022 iclr)
第一篇扩散模型DDPM做语义分割的，但是很水/离谱，感觉是蹭热度占坑的。
- 本文证明了扩散模型的中间表示含有语义信息，可以做分割。这里的“图片表示”选取的是扩散模型的U-Net的解码器每一阶段的特征图。文中将原图片增加噪声(x_t)，输入扩散模型的U-Net,将解码器不同阶段(block)的特征图上采样到原图片尺寸，叠起来后作为像素级的表征，并训练了一个MLP，对每个像素进行分类。
- 实验证明了，U-Net解码器中间阶段的特征图分割效果更好，这是直观的，因为解码器早期阶段刚开始解码，想从编码器的压缩表征中恢复原分辨率的分割图是困难的，而解码器在扩散模型中预训练时是用来预测噪声的，因此后期阶段的特征图含有更多噪声的信息。
- 实验还证明了输入图片的t越小，分割效果越好，这也是显然的，因为t越小噪声越小，信息损失越小。
- 文中通过上面两个实验证明了扩散模型的中间表示富含语义信息，我认为这是不太令人信服的。
- 具体的，文中将扩散模型应用到了一个半监督分割任务，先在无标签数据上训练扩散模型；再选了一个解码器阶段的子集，一个时间步t的子集，将一张有标签图片不同时间步输入模型、不同解码器阶段的特征图叠起来，作为表征输入MLP，得到分割掩码并监督训练。
- 实验部分也是不可信服的。作者对图片生成的两个数据集，人工标注了一批小数据集，和两个公开数据集，在这上面与一系列自监督/生成模型进行比较（都是利用中间表征，再MLP），以此表明扩散模型达到了sota。我认为，一方面，用的数据集不是Few shot领域常用的，如FSS-1000；另一方面，没有与其他成熟的半监督方法对比，并且与其他生成模型的对比也不令人信服，因为作者是直接把中间表征直接后接MLP做分割，可能对其他生成模型不合适/没有精心调参，不能证明作者选取的扩散模型的中间表征（噪声预测U-Net的特征图）比先前的好（MAE,GAN）

# Diffuse, Attend, and Segment: Unsupervised Zero-Shot Segmentation using Stable Diffusion(2023.8 google)
google的一篇文章，感觉有道理，在无监督分割上取得了很出色的效果
- 本文中利用的中间表征是，stable diffusion中transformer层里的自注意力图(h\*w\*h\*w)，认为，每个像素的注意力图中，属于同一对象类别的像素点可能有较大的值；属于同一对象类别的像素点的注意力图可能相似。不同分辨率的注意力图也有影响，分辨率较小的更适合识别大对象，较大的更适合识别小对象，文中使用了不同分辨率的注意力图。
- 为了利用stable diff，一方面，使用非条件的text作为输入，只进行一次迭代（t设置为300）
- Attention Aggregation：融合不同分辨率的注意力图。先将不同分辨率的注意力图的后两维上采样到64（最大尺寸），再融合不同尺寸，将低分辨率注意力图（如8^4），(0,0)位置的64\*64注意力图，与较高分辨率（如16^2）注意力图，(0,0),(0,1),(1,0),(1,1)相加，再依次与更高分辨率的注意力图融合。最终得到64^4的注意力图。
- Iterative Attention Merging：对融合后的注意力图，用对称KL散度衡量两个像素的注意力图的距离。在第一个迭代，对每一个像素，计算与其注意力图距离小于某个阈值的所有注意力图的均值，并替代原来的；在后面N-1个迭代中，对每个注意力图，计算与其注意力图距离小于某个阈值的所有注意力图的均值，用这个均值替代所有参与平均的注意力图，实现注意力图的合并。
- Non-Maximum Suppression:经过上面两步，得到N_p个object proposals，对每个像素点，取所有proposal的argmax，作为最终的预测。
- 实验部分，在流行的无监督数据集上，与其他无监督方法对比，提升显著，令人信服